{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5654b039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-1.12.0-cp39-cp39-win_amd64.whl (161.8 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.13.0-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-0.12.0-cp39-cp39-win_amd64.whl (969 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: requests in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.2)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.12.0 torchaudio-0.12.0 torchvision-0.13.0\n",
      "Collecting torch\n",
      "  Downloading torch-1.12.0-cp39-cp39-win_amd64.whl (161.8 MB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.13.0-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-0.12.0-cp39-cp39-win_amd64.whl (969 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rumma\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.12.0 torchaudio-0.12.0 torchvision-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1111074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e446d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e21c1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ff3c3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.4251e-26, 5.3109e-43, 9.4271e-26],\n",
      "        [5.3109e-43, 9.4246e-26, 5.3109e-43],\n",
      "        [9.4243e-26, 5.3109e-43, 9.4278e-26],\n",
      "        [5.3109e-43, 9.4265e-26, 5.3109e-43],\n",
      "        [9.4256e-26, 5.3109e-43, 9.4267e-26],\n",
      "        [5.3109e-43, 9.4248e-26, 5.3109e-43]])\n"
     ]
    }
   ],
   "source": [
    "#Randomly defined matrix\n",
    "a = torch.empty(6,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "201d1fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f5734d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8c0436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(4,3 , dtype=torch.long)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2391812a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbc8f929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting list into tensor\n",
    "a = [7.8,5]\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f3a1f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor(a)\n",
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d4205b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13796617",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4112/1860503752.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#torch always take numerical values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rumman'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ahmad'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "#torch always take numerical values\n",
    "a = torch.tensor(['rumman','ahmad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ead800d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.8000, 5.0000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([7.8,5])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff558ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c13c560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be29743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "275b56c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a  = [7.8,5]\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce6b5ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(a)\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc2df897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = a.new_ones(6,5 , dtype = torch.double) #new methods take in size\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca67053a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2639,  0.1914, -1.2224, -0.5177,  0.2817],\n",
      "        [ 0.3694, -0.0347, -0.7226, -0.2384, -1.7264],\n",
      "        [ 0.9469, -0.0411, -0.6082, -0.0358, -0.7482],\n",
      "        [ 0.0068,  1.4623, -0.0754,  1.0874, -0.5555],\n",
      "        [ 1.0118,  1.7031, -0.0965, -0.6364, -1.9258],\n",
      "        [ 1.7448,  2.5696, -0.4314, -0.0172,  0.0824]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn_like(a,dtype = torch.float)   #override dtype\n",
    "print(a)                                      #Result will be the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7a26a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 5])\n"
     ]
    }
   ],
   "source": [
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5709630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a9dcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd6876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b6887df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9409, 0.7892, 0.7601, 0.9179, 0.2514],\n",
      "        [0.8711, 0.2822, 0.2592, 0.4899, 0.3617],\n",
      "        [0.8281, 0.1324, 0.1047, 0.1347, 0.8947],\n",
      "        [0.3480, 0.3005, 0.7073, 0.9418, 0.2531],\n",
      "        [0.6505, 0.6852, 0.3301, 0.5871, 0.5763],\n",
      "        [0.3777, 0.9224, 0.5366, 0.6980, 0.3150]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.rand(6,5)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27fabf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2049,  0.9806, -0.4624,  0.4002,  0.5330],\n",
      "        [ 1.2405,  0.2476, -0.4634,  0.2516, -1.3647],\n",
      "        [ 1.7750,  0.0913, -0.5035,  0.0989,  0.1466],\n",
      "        [ 0.3548,  1.7628,  0.6319,  2.0292, -0.3025],\n",
      "        [ 1.6623,  2.3883,  0.2335, -0.0493, -1.3495],\n",
      "        [ 2.1225,  3.4920,  0.1052,  0.6807,  0.3975]])\n"
     ]
    }
   ],
   "source": [
    "#ADDITION\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a578df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd88365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1675dc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0004e-25],\n",
       "        [5.3109e-43, 2.4779e-26, 5.3109e-43, 3.5749e+14, 5.3109e-43],\n",
       "        [1.4013e-45, 0.0000e+00, 7.0065e-45, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.empty(6,5)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e963be82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2049,  0.9806, -0.4624,  0.4002,  0.5330],\n",
      "        [ 1.2405,  0.2476, -0.4634,  0.2516, -1.3647],\n",
      "        [ 1.7750,  0.0913, -0.5035,  0.0989,  0.1466],\n",
      "        [ 0.3548,  1.7628,  0.6319,  2.0292, -0.3025],\n",
      "        [ 1.6623,  2.3883,  0.2335, -0.0493, -1.3495],\n",
      "        [ 2.1225,  3.4920,  0.1052,  0.6807,  0.3975]])\n"
     ]
    }
   ],
   "source": [
    "torch.add(a,b , out = result)   #Providing as an argument\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af9e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "40b55e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9409, 0.7892, 0.7601, 0.9179, 0.2514],\n",
       "        [0.8711, 0.2822, 0.2592, 0.4899, 0.3617],\n",
       "        [0.8281, 0.1324, 0.1047, 0.1347, 0.8947],\n",
       "        [0.3480, 0.3005, 0.7073, 0.9418, 0.2531],\n",
       "        [0.6505, 0.6852, 0.3301, 0.5871, 0.5763],\n",
       "        [0.3777, 0.9224, 0.5366, 0.6980, 0.3150]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adds a to b\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2e777d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2639,  0.1914, -1.2224, -0.5177,  0.2817],\n",
       "        [ 0.3694, -0.0347, -0.7226, -0.2384, -1.7264],\n",
       "        [ 0.9469, -0.0411, -0.6082, -0.0358, -0.7482],\n",
       "        [ 0.0068,  1.4623, -0.0754,  1.0874, -0.5555],\n",
       "        [ 1.0118,  1.7031, -0.0965, -0.6364, -1.9258],\n",
       "        [ 1.7448,  2.5696, -0.4314, -0.0172,  0.0824]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da5154fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2049,  0.9806, -0.4624,  0.4002,  0.5330],\n",
       "        [ 1.2405,  0.2476, -0.4634,  0.2516, -1.3647],\n",
       "        [ 1.7750,  0.0913, -0.5035,  0.0989,  0.1466],\n",
       "        [ 0.3548,  1.7628,  0.6319,  2.0292, -0.3025],\n",
       "        [ 1.6623,  2.3883,  0.2335, -0.0493, -1.3495],\n",
       "        [ 2.1225,  3.4920,  0.1052,  0.6807,  0.3975]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44138e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c4a6601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2639,  0.1914, -1.2224, -0.5177,  0.2817],\n",
       "        [ 0.3694, -0.0347, -0.7226, -0.2384, -1.7264],\n",
       "        [ 0.9469, -0.0411, -0.6082, -0.0358, -0.7482],\n",
       "        [ 0.0068,  1.4623, -0.0754,  1.0874, -0.5555],\n",
       "        [ 1.0118,  1.7031, -0.0965, -0.6364, -1.9258],\n",
       "        [ 1.7448,  2.5696, -0.4314, -0.0172,  0.0824]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Index\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2d90f846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2639,  0.1914, -1.2224, -0.5177,  0.2817])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18646547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1914)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "12d80df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1914, -0.0347, -0.0411,  1.4623,  1.7031,  2.5696])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "88d84cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2224, -0.5177],\n",
       "        [-0.7226, -0.2384],\n",
       "        [-0.6082, -0.0358],\n",
       "        [-0.0754,  1.0874],\n",
       "        [-0.0965, -0.6364],\n",
       "        [-0.4314, -0.0172]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,[2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9740d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "725fdfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View (it is used for reshape or resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "789d024f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4307,  1.4959,  0.0998],\n",
       "        [-0.5226, -0.2474, -0.0542],\n",
       "        [ 0.5317, -0.3530, -1.4957]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "60d74748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d879b57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4307,  1.4959,  0.0998, -0.5226, -0.2474, -0.0542,  0.5317, -0.3530,\n",
       "        -1.4957])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.view(9)         #coverted to 1row and 9 columns\n",
    "b                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d0d91ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "476e1db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4307,  1.4959,  0.0998, -0.5226, -0.2474, -0.0542,  0.5317, -0.3530,\n",
       "         -1.4957]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.view(-1 , 9)   #the size -1 is inferred from other dimensions\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "933b5c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f86825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3206dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aa572281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting a torch tensor to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4aafca50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "19f8f149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e319cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e337e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a8d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf053e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b003a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb5249c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430727dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3364e40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea291dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a3f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a68a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84375261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b570b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53815887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32087373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e3b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b80af3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dcd9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9969455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ca656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ac565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9a0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d21474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927ae60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c97ef84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
